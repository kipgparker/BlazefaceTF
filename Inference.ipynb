{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute dtype: float16\n",
      "Variable dtype: float32\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvB(x, layers):\n",
    "    residual = x\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(layers, (3, 3),padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(layers, (3, 3),padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(layers, (3, 3),padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = add([x, residual])\n",
    "    return x  \n",
    "\n",
    "def ConvA(x, layers):\n",
    "    residual = Conv2D(layers, (1, 1),strides=(2, 2),padding='same',use_bias=False)(x)\n",
    "    residual = BatchNormalization(axis=channel_axis)(residual)\n",
    "    x = SeparableConv2D(layers, (3, 3), padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(layers, (3, 3),padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = MaxPooling2D((3, 3),strides=(2, 2),padding='same',)(x)\n",
    "    x = add([x, residual])\n",
    "    return x  \n",
    "\n",
    "def ConvC(x, layers):\n",
    "    residual = Conv2D(512, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization(axis=channel_axis)(residual)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(512, (3, 3),padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(512, (3, 3),padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = MaxPooling2D((3, 3),strides=(2, 2),padding='same')(x)\n",
    "    x = add([x, residual])\n",
    "    x = SeparableConv2D(728, (3, 3),padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(1024, (3, 3),padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_axis = 1\n",
    "\n",
    "inputs = Input(shape=(224,224,48))\n",
    "x = Conv2D(128, (3, 3),strides=(2, 2),use_bias=False, padding='SAME')(inputs)\n",
    "x = BatchNormalization(axis=channel_axis)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(128, (3, 3), use_bias=False, padding='SAME')(x)\n",
    "x = BatchNormalization(axis=channel_axis)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = ConvA(x, 256)\n",
    "x = ConvA(x, 512)\n",
    "\n",
    "x = ConvB(x, 512)\n",
    "x = ConvB(x, 512)\n",
    "#x = ConvB(x, 728)\n",
    "#\n",
    "x = ConvC(x, 728)\n",
    "#\n",
    "x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "outputs = Dense(1, activation='sigmoid', name='predictions', dtype='float32')(x)\n",
    "#outputs = Activation('softmax', dtype='float32')(x)\n",
    "#x = Dense(1, activation='sigmoid', name='predictions')(x)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "#model.summary()\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-4)\n",
    "adam = Adam(learning_rate=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(0,1,(1000, 224, 224, 48))\n",
    "y = np.random.uniform(0,1,(1000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x, y,\n",
    "                    batch_size=16,\n",
    "                    epochs=5,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim#Dimension is easy enough\n",
    "        self.batch_size = batch_size#So is batch size\n",
    "        self.labels = labels#\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.utils.data_utils.Sequence"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit = plt.imread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('D:\\\\faces\\\\data.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data['data'])):\n",
    "    data['data'][i]['location'] = data['data'][i]['location'][:len(data['data'][i]['location'])-4]\n",
    "    #data['data'][i]['location'] = data['data'][i]['location']+'.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\\\faces\\\\data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422382"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [os.path.join('D:\\\\faces\\\\f1\\\\'+file) for file in os.listdir('D:\\\\faces\\\\f1')]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6651558876037598\n"
     ]
    }
   ],
   "source": [
    "class dataloader(tf.keras.utils.Sequence):\n",
    "    #Generates data for keras\n",
    "    def __init__(self, data_path, list_IDs, batch_size=16, dim=(224,224), n_channels=48,shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        with open(data_path, 'r') as f:\n",
    "            self.data = json.load(f)['data']\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels), dtype = np.float32)\n",
    "        y = np.empty((self.batch_size), dtype=np.float32)\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            X[i,] = self.get_frames(ID)\n",
    "            \n",
    "        return X, y        \n",
    "    \n",
    "            \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "    \n",
    "    def get_frames(self, index):\n",
    "        data = self.data[index]\n",
    "        #x = np.empty((*self.dim, self.n_channels), dtype = np.float32)\n",
    "        file_name = data['location']\n",
    "        num_faces = data['face_count']\n",
    "        a = 0\n",
    "        if (num_faces > 1):\n",
    "            a = np.random.randint(0,num_faces)\n",
    "        frame_count = data['frames'][a]\n",
    "        offset = np.random.randint(0,frame_count-16)\n",
    "        \n",
    "        x = np.dstack([self.load_image(file_name+'_'+str(a)+'_'+str(i)+'.png') for i in range(offset, offset+16)])\n",
    "        #x = np.dstack([dl.load_image(dl.data[index]['location']+'_'+str(0)+'_'+str(h)+'.png') for h in range(16)])\n",
    "        return x\n",
    "    \n",
    "    def load_image(self, path):\n",
    "        img = cv2.imread(path)\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)/255.0\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "dl = dataloader('D:\\\\faces\\\\data.json',np.arange(100),dim = (224,224))\n",
    "#%timeit X = dl.__getitem__(0)\n",
    "#%timeit X = dl.get_frames(10)\n",
    "\n",
    "start = time.time()\n",
    "X = [dl.get_frames(i+100) for i in range(16)]\n",
    "end = time.time()\n",
    "\n",
    "s\n",
    "\n",
    "def lol():\n",
    "    \n",
    "    for i in range(16):\n",
    "        x = np.dstack([dl.load_image(dl.data[i]['location']+'_'+str(0)+'_'+str(h)+'.png') for h in range(100, 100+16)])        \n",
    "%timeit lol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.02 ms ± 3.28 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "595 µs ± 1.08 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "1.2 ms ± 3.06 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "670 µs ± 2.05 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cv2.imread('D://faces//aaqaifqrwn_0_0.png')\n",
    "%timeit cv2.imread('D://faces//aaqaifqrwn_0_0.jpg')\n",
    "%timeit plt.imread('D://faces//aaqaifqrwn_0_0.png')\n",
    "%timeit plt.imread('D://faces//aaqaifqrwn_0_0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,15):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-206-b61707b36785>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIsAAACICAYAAADXjRhRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABqUlEQVR4nO3VwU0DUQxAwf2IEjZntv9akiJyhh5MA4n0IhERxMzVPvjwJK+Z2aB4++0D+DvEQiYWMrGQiYVMLGTvjyzv+z7HcTzpFF7B5XL5mpnTrdlDsRzHsZ3P55+5ipe01rrem3lDZGIhEwuZWMjEQiYWMrGQiYVMLGRiIRMLmVjIxEImFjKxkImFTCxkYiETC5lYyMRCJhYysZCJhUwsZGIhEwuZWMjEQiYWMrGQiYVMLGRiIRMLmVjIxEImFjKxkImFTCxkYiETC5lYyMRCJhYysZCJhUwsZGIhEwuZWMjEQiYWMrGQiYVMLGRiIRMLmVjIxEImFjKxkImFTCxkYiETC5lYyMRCJhYysZCJhUwsZGIhEwuZWMjEQiYWMrGQiYVMLGRiIRMLmVjIxEImFjKxkImFTCxkYiETC5lYyMRCJhYysZCJhUwsZGIhEwuZWMjEQiYWMrGQiYVMLGRiIRMLmVjIxEImFjKxkImFTCxkYiETC5lYyNbM9OW1Prdtuz7vHF7Ax8ycbg0eioX/zRsiEwuZWMjEQiYWMrGQiYVMLGRiIfsGp5oasVS0OhcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X[:,:,i*3:(i*3)+3])\n",
    "    plt.xlabel('b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gathery():\n",
    "        a = 0\n",
    "        if (3 > 1):\n",
    "            a = np.random.randint(0,3)\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    " X = np.empty((*dl.dim, dl.n_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'D:\\\\faces\\\\f1\\\\aymlynzeni',\n",
       " 'label': 0,\n",
       " 'face_count': 2,\n",
       " 'frames': [300, 299],\n",
       " 'original': 'doniqevxeg.mp4'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dl.data['face_count']\n",
    "dl.data[46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
